{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "37b0e94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "1523933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import nnx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import lax\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "600c7e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'layers' from '/home/tianjiao/learn-jax/layers.py'>"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import layers as L\n",
    "\n",
    "importlib.reload(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7c4e786",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../assets/红楼梦.txt\", \"r\") as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "db18dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\n",
    "for i in range(0, 10):\n",
    "    for j in range(0, 10):\n",
    "        s = f\"{i}+{j}={i + j}\\n\"\n",
    "        data += s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "ec33f2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab:  ...\n",
      "vocab len: 13\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(list(set(data)))\n",
    "print(\"vocab: \" + \"\".join(vocab[:-50]) + \" ...\")\n",
    "print(f\"vocab len: {len(vocab)}\")\n",
    "\n",
    "stoi = {ch: i for i, ch in enumerate(vocab)}\n",
    "iots = {i: ch for i, ch in enumerate(vocab)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: \"\".join([iots[i] for i in l])\n",
    "train_data = jnp.array(encode(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "86c6f599",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "# context window length\n",
    "block_size = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "8198d167",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_slice_vmap = jax.vmap(lax.dynamic_slice, in_axes=(None, 0, None))\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def get_batch(random_key, data):\n",
    "    ix = jax.random.randint(\n",
    "        random_key, shape=(batch_size, 1), minval=0, maxval=len(data) - block_size\n",
    "    )\n",
    "    x = dynamic_slice_vmap(data, ix, (block_size,))\n",
    "    y = dynamic_slice_vmap(data, ix + 1, (block_size,))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "1ea74150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, x, y):\n",
    "    logits = model(x)\n",
    "    return optax.softmax_cross_entropy_with_integer_labels(logits, labels=y).mean()\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model, optimizer, key):\n",
    "    key, subkey = jax.random.split(key)\n",
    "    batch = get_batch(key, train_data)\n",
    "    loss, grads = nnx.value_and_grad(loss_fn)(model, *batch)\n",
    "    optimizer.update(model, grads)\n",
    "    return loss, key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "1c195c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embed_dim = 8\n",
    "qk_dim = 32\n",
    "hidden_dim = 4 * embed_dim\n",
    "layer_count = 1\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model = L.MicroLM(\n",
    "    L.MicroLMConfig(vocab_size, embed_dim, qk_dim, hidden_dim, block_size, layer_count),\n",
    "    rngs=nnx.Rngs(params=0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "27b61e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "954da886",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = nnx.Optimizer(model, optax.adam(learning_rate), wrt=nnx.Param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "18459fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "961c9ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0\t train loss: 2.6081106662750244\n",
      "step: 1000\t train loss: 1.6376978158950806\n",
      "step: 2000\t train loss: 1.1147936582565308\n",
      "step: 3000\t train loss: 0.7417328953742981\n",
      "step: 4000\t train loss: 0.22384488582611084\n",
      "step: 5000\t train loss: 0.0853957012295723\n",
      "step: 6000\t train loss: 0.0856800526380539\n",
      "step: 7000\t train loss: 0.13447034358978271\n",
      "step: 8000\t train loss: 0.09790881723165512\n",
      "step: 9000\t train loss: 0.06301579624414444\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    loss, key = train_step(model, optimizer, key)\n",
    "    all_train_losses.append(loss)\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"step: {i}\\t train loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "8e53b1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.partial(jax.jit, static_argnames=[\"length\"])\n",
    "def generate_text(model, key, length, initial):\n",
    "    def scan_gen(carry, _):\n",
    "        key, context = carry\n",
    "        logits = model(context)\n",
    "        key, subkey = jax.random.split(key)\n",
    "        new_token = jax.random.categorical(subkey, logits[-1], shape=(1,))\n",
    "        context = jnp.concatenate([context[1:], new_token])\n",
    "        return (key, context), new_token\n",
    "\n",
    "    _, new_tokens = lax.scan(scan_gen, (key, initial), (), length=length)\n",
    "    return new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "da0162ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_initial(text: str):\n",
    "    s = encode(text)\n",
    "    assert len(s) < block_size\n",
    "    return jnp.concatenate(\n",
    "        [\n",
    "            jnp.zeros((block_size - len(s),), dtype=jnp.int32),\n",
    "            jnp.array(s, dtype=jnp.int32),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def completion(input: str, length: int):\n",
    "    result = generate_text(model, key, length, compute_initial(input))[:, 0].tolist()\n",
    "    return input + decode(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "f0152e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1+0=7\n",
      "1+\n"
     ]
    }
   ],
   "source": [
    "print(completion(\"1+0=\", 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
